{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECOMMENDER SYSTEM WITH PYSPARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to use pyspark for the implementation of a movies recommender (or recommendation) system.<br>\n",
    "\n",
    "For this puspose, we will use the famous MoviLens dataset.<br>\n",
    "We will use the small version to avoid memory limitations on CPU implementations.\n",
    "\n",
    "Our recommender system will be based on the alternating least squares (ALS) algorithm.\n",
    "\n",
    "We will train our model and test it using evaluation metrics such as: RMSE, Recall and MAP.\n",
    "\n",
    "Finally, we will use our model to recommend movies to a new user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of this notebook is as follows:\n",
    "\n",
    "1. FIRST STEPS:<br>\n",
    "    1.1) Create Spark Session<br>\n",
    "    1.2) Import data_sets\n",
    "2. DATA PREPROCESSING\n",
    "3. RECOMMENDER SYSTEM<br>\n",
    "    3.1) Data_sets: training, validation and test<br>\n",
    "    3.2) Quick look at the model (ALS)<br>\n",
    "    3.3) Hyperparameters tuning\n",
    "4. TEST<br>\n",
    "    4.1) RMSE from the test data_set<br>\n",
    "    4.2) Additional metrics: Recall and MAP<br>\n",
    "5. OUR RECOMMENDER SYSTEM IN ACTION\n",
    "6. CONCLUSIONS\n",
    "7. ACKNOWLEDGMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FIRST STEPS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Create Spark Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create our Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.41:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6e744849b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Import data_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the MoviLens dataset from their web page (https://movielens.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datasets_path = os.path.join('.','datasets')\n",
    "\n",
    "small_dataset_path = os.path.join(datasets_path,'ml-latest-small.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "small_f = urllib.request.urlretrieve(small_dataset_url, small_dataset_path)\n",
    "\n",
    "#WARNING: To be run just for the first time. Then, comment it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "\n",
    "#WARNING: To be run just for the first time. Then, comment it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small','ratings.csv')\n",
    "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will create an RDD for each data_set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_raw_data = ss.sparkContext.textFile(small_ratings_file)\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'userId,movieId,rating,timestamp'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see the name of the columns:\n",
    "small_ratings_raw_data_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_movies_raw_data = ss.sparkContext.textFile(small_movies_file)\n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movieId,title,genres'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see the name of the columns:\n",
    "small_movies_raw_data_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether titles are unique or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will transform RDDs into DataFrames to work with them more efficiently:\n",
    "#(We will take the columns we need only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|item|               title|\n",
      "+----+--------------------+\n",
      "|   1|    Toy Story (1995)|\n",
      "|   2|      Jumanji (1995)|\n",
      "|   3|Grumpier Old Men ...|\n",
      "+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df =  ss.createDataFrame(small_movies_data,[\"item\", \"title\"])\n",
    "movies_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df =  ss.createDataFrame(small_ratings_data,[\"user\", \"item\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.select(['item']).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9624"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.select(['title']).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more number of different movies than corresponding titles' .... what means that some movies have more than one key.<br>\n",
    "Keys must be unique, so let's solve this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9624"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, we will create a column with unique records of each movie:\n",
    "\n",
    "movies_unique_titles = movies_df.select(['title']).distinct()\n",
    "movies_unique_titles.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, we will index the movie titles with a consecutive serie of numbers (using SQL):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_unique_titles.registerTempTable('movies_unique_titles_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_index = ss.sql('select row_number() over (order by \"title\") as itemId, * from movies_unique_titles_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|itemId|               title|\n",
      "+------+--------------------+\n",
      "|     1|    Fair Game (1995)|\n",
      "|     2| If Lucy Fell (1996)|\n",
      "|     3|           \"Birdcage|\n",
      "|     4| Three Wishes (1995)|\n",
      "|     5|Heavenly Creature...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_index.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9624"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check control: All the movies are included\n",
    "movies_index.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9624"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check control: There is one and only one key for each movie\n",
    "movies_index.select('itemId').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a dataframe with the correspondence between the original indexes \n",
    "#(which include some different indexes matching the same movies) and the new unique index for each movie:\n",
    "\n",
    "movies_corr = movies_df.join(movies_index,on=['title'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------+\n",
      "|               title| item|itemId|\n",
      "+--------------------+-----+------+\n",
      "|\"Abominable Dr. P...| 4195|    24|\n",
      "|           \"Birdcage|  141|     3|\n",
      "|      \"International|66198|    43|\n",
      "|              \"Jetée| 8477|    28|\n",
      "| \"Life Less Ordinary| 1658|    13|\n",
      "+--------------------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_corr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check control: All the original indexes are included\n",
    "movies_corr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9624"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check control: All the unique new keys are included\n",
    "movies_corr.select(['itemId']).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use this correspondence dataframe to double check whether there are more that one original index\n",
    "#for some movies.\n",
    "#For this purpose, we create a RDD with the new indexes and their corresponding list of repeated original\n",
    "#indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_duplicates = movies_corr.rdd.map(lambda x: (x[2],x[0])).groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9624"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Control: the number of rows of this RDD must be the same as the number of new indexes\n",
    "movies_duplicates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, we will define a function to count the number of original indexes per movie (and new index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_duplicates(movies_list):\n",
    "    return int(len(movies_list[1])), int(movies_list[0]), movies_list[1]\n",
    "\n",
    "movie_duplicates_count = movies_duplicates.map(count_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(duplic=2, id=5200, movies=Row(data=['\"Signal', '\"Signal'], index=0, maxindex=2)),\n",
       " Row(duplic=2, id=1803, movies=Row(data=['\"Bourne Identity', '\"Bourne Identity'], index=0, maxindex=2)),\n",
       " Row(duplic=2, id=7804, movies=Row(data=['\"Ladykillers', '\"Ladykillers'], index=0, maxindex=2)),\n",
       " Row(duplic=2, id=205, movies=Row(data=['\"Apartment', '\"Apartment'], index=0, maxindex=2)),\n",
       " Row(duplic=2, id=7610, movies=Row(data=['\"Sex', '\"Sex'], index=0, maxindex=2)),\n",
       " Row(duplic=2, id=212, movies=Row(data=['\"Thing', '\"Thing'], index=0, maxindex=2))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And we will use these information to build a dataframe with:\n",
    "#the new index, their corresponding number of repeated original indexes and the title of their \n",
    "#related movies.\n",
    "movie_duplicates_count_df = movie_duplicates_count.toDF(['duplic','id','movies'])\n",
    "\n",
    "#We will filter those movies with more that one original index:\n",
    "movie_duplicates_count_df.filter(movie_duplicates_count_df['duplic']>1).take(6) #We show a sample of 6 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that we were right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we will include a column with the new keys on the 'ratings' data_frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's have a look at the number of rows of the 'ratings' data_frame:\n",
    "ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We add the new_key column ('itemId'):\n",
    "ratings_corrected_df = ratings_df.join(movies_corr, on=['item'], how='left')\n",
    "\n",
    "#And we check whether every original row is still there\n",
    "ratings_corrected_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9607"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check how many new keys are included on the new column\n",
    "ratings_corrected_df.select(['itemId']).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number is lower than the total number of movies because there are movies that have never\n",
    "#been rated by any user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+--------------------+------+\n",
      "|  item|user|rating|               title|itemId|\n",
      "+------+----+------+--------------------+------+\n",
      "|100553| 105|   4.5|Frozen Planet (2011)|  5659|\n",
      "|100553| 318|   4.5|Frozen Planet (2011)|  5659|\n",
      "|102684| 249|   3.5|Only God Forgives...|  9613|\n",
      "|102684| 380|   4.0|Only God Forgives...|  9613|\n",
      "|  1090|   1|   4.0|      Platoon (1986)|  9413|\n",
      "+------+----+------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Taking a look at the new data_frame for ratings:\n",
    "ratings_corrected_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final data_sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cache the corrected data_sets as they are the data_sets we are going to use in this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[itemId: int, title: string]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our list of movies:\n",
    "movies_index.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our list of ratings: \n",
    "#We keep the columns we really need only (user, itemId and rating)\n",
    "\n",
    "ratings_corrected_final_rdd = ratings_corrected_df.rdd.map(lambda x: (int(x[1]),int(x[4]),float(x[2]))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpersist cached RDDs that are not be used in this project anymore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[7] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_movies_data.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[3] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RECOMMENDER SYSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will base our recommendations on collabotative filtering  and matrix factorization.\n",
    "\n",
    "Spark.ml supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. <br>\n",
    "Spark.ml uses the alternating least squares (ALS) algorithm to learn these latent factors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(105, 5659, 4.5), (318, 5659, 4.5), (249, 9613, 3.5)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's have a look at our data_set again:\n",
    "ratings_corrected_final_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Data_sets: training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[324] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create train and test data_sets:\n",
    "\n",
    "training_RDD, test_RDD = ratings_corrected_final_rdd.randomSplit([8, 2], seed=42)\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "#Need to cache the data to speed up training\n",
    "training_RDD.cache()\n",
    "test_RDD.cache()\n",
    "\n",
    "## NOTE: We will carry out the validation process using cross_validation technique on the training data_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(59, 9413, 4.0), (64, 9413, 5.0), (83, 9413, 1.5)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(59, 9413), (64, 9413), (83, 9413)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_predict_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80671 20165\n"
     ]
    }
   ],
   "source": [
    "#Check control: Distribution of the original data_set:\n",
    "print(training_RDD.count(),test_RDD.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Quick look at the model (ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS,MatrixFactorizationModel, Rating\n",
    "\n",
    "seed = 42\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "rank = 5 \n",
    "\n",
    "model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,lambda_=regularization_parameter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " array('d', [-0.0350075326859951, -0.18089444935321808, 0.9677019715309143, -0.12788857519626617, -1.0125657320022583]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the latent features for one product\n",
    "model.productFeatures().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100,\n",
       "  array('d', [0.41765549778938293, 0.7986670136451721, 1.2712528705596924, -0.9706224799156189, -0.8453475832939148]))]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the latent features for one user\n",
    "model.userFeatures().take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=53, product=242, rating=3.7267663426784754),\n",
       " Rating(user=360, product=242, rating=3.5275400909342216),\n",
       " Rating(user=243, product=242, rating=3.51589959464369),\n",
       " Rating(user=393, product=242, rating=3.5013989423263823),\n",
       " Rating(user=452, product=242, rating=3.423343666810384),\n",
       " Rating(user=12, product=242, rating=3.418763211697275),\n",
       " Rating(user=154, product=242, rating=3.4111653761396212),\n",
       " Rating(user=327, product=242, rating=3.371480869339484),\n",
       " Rating(user=548, product=242, rating=3.368568316929615),\n",
       " Rating(user=441, product=242, rating=3.3492286076305833)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Product X, Find N Users to Sell To\n",
    "model.recommendUsers(242,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=196, product=4415, rating=4.858206214589),\n",
       " Rating(user=196, product=6026, rating=4.85741371607064),\n",
       " Rating(user=196, product=3510, rating=4.852153724357697),\n",
       " Rating(user=196, product=4701, rating=4.8187556069240465),\n",
       " Rating(user=196, product=6406, rating=4.79168014246466),\n",
       " Rating(user=196, product=158, rating=4.757341308809968),\n",
       " Rating(user=196, product=2340, rating=4.747375284990344),\n",
       " Rating(user=196, product=2921, rating=4.745887407209832),\n",
       " Rating(user=196, product=4776, rating=4.712530087031055),\n",
       " Rating(user=196, product=1954, rating=4.709794682479856)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For User Y Find N Products to Promote\n",
    "model.recommendProducts(196,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.418763211697275"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict Single Product for Single User\n",
    "model.predict(12, 242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.747375284990344"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict Single Product for Single User\n",
    "model.predict(196, 2340)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Hyperparameters tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try to optimize the hyperparamenters of the model.\n",
    "\n",
    "Most important hyper-params in Alternating Least Square (ALS):\n",
    "\n",
    "- maxIter: the maximum number of iterations to run\n",
    "- rank: the number of latent factors in the model\n",
    "- regParam: the regularization parameter in ALS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we need to translate the RDD for training into a data_frame: \n",
    "training_ratings_df = ss.createDataFrame(training_RDD,[\"user\", \"item\", \"rating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#We set a seed just in case we need to replicate results.\n",
    "seed = 42\n",
    "\n",
    "#Building the model:\n",
    "alsExplicit = ALS(userCol=\"user\", itemCol=\"item\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "\n",
    "#Feeding the model with the data_frame:\n",
    "defaultModel = alsExplicit.fit(training_ratings_df)\n",
    "\n",
    "#Setting the hyperparamenters grid:\n",
    "paramMapExplicit = ParamGridBuilder() \\\n",
    "                    .addGrid(alsExplicit.rank, [2,8, 12]) \\\n",
    "                    .addGrid(alsExplicit.maxIter, [5,10,20,30,50]) \\\n",
    "                    .addGrid(alsExplicit.regParam, [0.01,0.05,0.1,0.5,1.0,2]) \\\n",
    "                    .build()\n",
    "\n",
    "#Setting metric for evaluation purposes:\n",
    "evaluatorR = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "#Setting up the cross_validated grid search of the best hyperparameter over the hyperparameters grid. \n",
    "cvExplicit = CrossValidator(seed=seed, estimator=alsExplicit, estimatorParamMaps=paramMapExplicit, evaluator=evaluatorR, numFolds=3)\n",
    "\n",
    "#Feeding the cross_validated grid search with the data_frame:\n",
    "cvModelExplicit = cvExplicit.fit(training_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we are going to collect the best hyperparameters from the cross_validated grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = cvModelExplicit.bestModel\n",
    "best.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_cv = cvModelExplicit.avgMetrics\n",
    "\n",
    "for i,n in enumerate(metrics_cv):\n",
    "    if n == min(metrics_cv):\n",
    "        best_position = i\n",
    "best_param_cv = list(zip(cvModelExplicit.avgMetrics, paramMapExplicit))[best_position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9236690660432525,\n",
       " {Param(parent='ALS_462e7cb3aa5a', name='rank', doc='rank of the factorization'): 2,\n",
       "  Param(parent='ALS_462e7cb3aa5a', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
       "  Param(parent='ALS_462e7cb3aa5a', name='regParam', doc='regularization parameter (>= 0).'): 0.1})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can find the best RMSE obtained in the hyperparameters optimization process and the corresponding hyperparamenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TEST:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) RMSE from the test data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we are going to train our ALS model with the best parameters we have gotten.\n",
    "#Then, we will use this model to make predictions for the test data_set and,\n",
    "#we will use the RMSE metric to evalute our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.8787836373243412\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 42\n",
    "best_rank = list(best_param_cv[1].values())[0] #2\n",
    "best_iterations = list(best_param_cv[1].values())[1] #20\n",
    "best_reg_parameter=list(best_param_cv[1].values())[2] #0.1\n",
    "\n",
    "\n",
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=best_iterations,\n",
    "                      lambda_=best_reg_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the test RMSE is very similar to training's (or even better),\n",
    "# It seems that the model can generalize properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Additional metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use two additional metrics to check our model performance and reliability:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4.2.a) Recall:** normalized recall to measure the relevance of the recommendations without taking into account their order.\n",
    "\n",
    "### $$\\mathrm{recall}@N = \\frac{\\sum_{i=1}^N rel_i}{\\mathrm{min}(N, \\sum_{i\\in \\mathcal{I}_u} 1})$$\n",
    "\n",
    "    This way, results are normalized to 1 always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_n(N, test, recommended, train=None):\n",
    "    \"\"\"\n",
    "    :param N: number of recommendations\n",
    "    :param test: list of movies seen by user in test\n",
    "    :param train: list of movies seen by user in train. This has to be removed from the recommended list \n",
    "    :param recommended: list of movies recommended\n",
    "    \n",
    "    :return the recall\n",
    "    \"\"\"\n",
    "    if train is not None: # Remove items already in train\n",
    "        rec_true = [r for r in recommended if r not in train]        \n",
    "    else:\n",
    "        rec_true = recommended \n",
    "        \n",
    "    intersection = len(set(test) & set(rec_true[:N]))\n",
    "    \n",
    "    return intersection / float(min(N, len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4.2.b) Mean Averaged Precision (MAP)**:<br>\n",
    "Previous metrics did not account for the ranking of the recommendation, i.e. the relative position of a movie within the sorted list of recommendations.\n",
    "MAP does.\n",
    "\n",
    "    The Average Precision is definied as:\n",
    "\n",
    "### $$\\mathrm{AP}@N = \\frac{\\sum_{k=1}^N P(k) \\times rel(k)}{\\mathrm{min}(N, \\sum_{i\\in \\mathcal{I}_u} 1)}$$\n",
    "\n",
    "where $P(k)$ is the precision at cut-off in the item list, i.e. the ratio of the number of recommended items adopted, up to the position k, over the number k. Thus:\n",
    "\n",
    "### $$\\mathrm{AP}@N = \\frac{\\sum_{k=1}^N \\left(\\sum_{i=1}^k rel(i)\\right)/k \\times rel(k)}{\\mathrm{min}(N, \\sum_{i\\in \\mathcal{I}_u} 1)}$$\n",
    "\n",
    "    (See http://fastml.com/what-you-wanted-to-know-about-mean-average-precision/)\n",
    "\n",
    "\n",
    "Function taken from:\n",
    "    https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(N, test, recommended, train=None):\n",
    "    \"\"\"\n",
    "    Computes the average precision at N given recommendations.\n",
    "    \n",
    "    :param N: number of recommendations\n",
    "    :param test: list of movies seen by user in test\n",
    "    :param train: list of movies seen by user in train. This has to be removed from the recommended list \n",
    "    :param recommended: list of movies recommended\n",
    "    \n",
    "    :return The average precision at N over the test set\n",
    "    \"\"\"\n",
    "    if train is not None: \n",
    "        rec_true = []\n",
    "        for r in recommended:\n",
    "            if r not in train:\n",
    "                rec_true.append(r)\n",
    "    else:\n",
    "        rec_true = recommended    \n",
    "    predicted = rec_true[:N] # top-k predictions\n",
    "    \n",
    "    score = 0.0 # This will store the numerator\n",
    "    num_hits = 0.0 # This will store the sum of rel(i)\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in test and p not in predicted[:i]: #MIO: the purpose of \"not in predicted[:i]\" is to ensure there isn´t any duplicate\n",
    "            num_hits += 1.0\n",
    "            score += num_hits/(i+1.0)\n",
    "\n",
    "\n",
    "    return score / min(len(test), N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the implementation of both additional metrics, we need to build a data_frame that includes the following information for each user:\n",
    "    - The movies with high rates (>=4) in training and test data_sets.\n",
    "    - Recommended movies sorted by rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|user|     item_list_train|\n",
      "+----+--------------------+\n",
      "|  26|[1827, 881, 7745,...|\n",
      "| 474|[3304, 356, 9032,...|\n",
      "|  29|[844, 6491, 510, ...|\n",
      "+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions\n",
    "trainUsersGrouped = training_ratings_df.filter(training_ratings_df['rating']>=4).select('user','item').groupby('user').agg(functions.collect_set('item').alias('item_list_train'))\n",
    "trainUsersGrouped.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|user|      item_list_test|\n",
      "+----+--------------------+\n",
      "| 474|[4495, 1068, 6927...|\n",
      "|  29|[9358, 4938, 82, ...|\n",
      "| 418|[3427, 5895, 8102...|\n",
      "+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ratings_df = ss.createDataFrame( test_RDD, [\"user\", \"item\", \"rating\"])\n",
    "testUsersGrouped = test_ratings_df.filter(test_ratings_df['rating']>=4).select('user','item').groupby('user').agg(functions.collect_set('item').alias('item_list_test'))\n",
    "testUsersGrouped.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_col(x):\n",
    "    return x[0],(x[2],x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_only(x):\n",
    "    return x[0], [i[1] for i in x[1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|user|      item_list_pred|\n",
      "+----+--------------------+\n",
      "| 474|[6041, 4040, 9301...|\n",
      "|  29|[4938, 796, 5673,...|\n",
      "|  26|[7832, 2162, 1870...|\n",
      "|  65|[3869, 1300, 5236...|\n",
      "| 418|[7745, 400, 8102,...|\n",
      "| 558|[1300, 5222, 6393...|\n",
      "+----+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predictAll(test_for_predict_RDD)\n",
    "test_predict_df = ss.createDataFrame( test_preds, [\"user\", \"item\", \"rating\"])\n",
    "\n",
    "PredUsersGrouped = test_predict_df.rdd.map(zip_col).toDF([\"user\",\"item_rate\"]).groupby('user').agg(functions.sort_array(functions.collect_set('item_rate'),asc=False).alias('item_list'))\n",
    "\n",
    "PredUsersRank = PredUsersGrouped.rdd.map(item_only).toDF([\"user\",\"item_list_pred\"])\n",
    "\n",
    "PredUsersRank.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check whether we have gotten what we are looking for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(rating)=4.230414561253497)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_df.filter(test_predict_df['user'] == '65').agg({\"rating\":\"max\"}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user=65, item_list=[Row(_1=4.230414561253497, _2=3869), Row(_1=4.032184338366392, _2=1300), Row(_1=3.927514728445658, _2=5236), Row(_1=3.8808185829599324, _2=6570), Row(_1=3.865653497051426, _2=3368), Row(_1=3.820906888708919, _2=4266), Row(_1=3.7658954913448497, _2=2222), Row(_1=3.6476676693615673, _2=6690)])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredUsersGrouped.filter(PredUsersGrouped['user']=='65').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+\n",
      "|user|     item_list_train|      item_list_test|      item_list_pred|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "|  29|[844, 6491, 510, ...|[9358, 4938, 82, ...|[4938, 796, 5673,...|\n",
      "| 474|[3304, 356, 9032,...|[4495, 1068, 6927...|[6041, 4040, 9301...|\n",
      "|  65|[1591, 3616, 4938...|[6690, 2222, 4266...|[3869, 1300, 5236...|\n",
      "| 191|[7282, 6346, 7049...|[4226, 4938, 3446...|[5301, 5425, 5571...|\n",
      "| 418|[9510, 5105, 1425...|[3427, 5895, 8102...|[7745, 400, 8102,...|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataForMetrics = trainUsersGrouped.join(testUsersGrouped, on=['user']).join(PredUsersRank, on=['user'])\n",
    "\n",
    "dataForMetrics.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data_frame that includes all the data we need. <br>\n",
    "\n",
    "Now, we will calculate metrics for the first (5,10,30, ...) recommendations provided by our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@5=0.801\n",
      "map@5=0.689\n",
      "recall@10=0.857\n",
      "map@10=0.701\n",
      "recall@30=0.921\n",
      "map@30=0.719\n",
      "recall@50=0.948\n",
      "map@50=0.731\n",
      "recall@100=0.973\n",
      "map@100=0.743\n"
     ]
    }
   ],
   "source": [
    "for k in [5, 10, 30, 50, 100]:\n",
    "    recalls_sum, recalls_count = \\\n",
    "    dataForMetrics.rdd.map(lambda x: recall_at_n(k,x[2],x[3],x[1])).map(lambda x: (x,1)).reduce(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "    recall = recalls_sum/recalls_count\n",
    "    print(\"recall@%s=%.3f\" %(k, recall))\n",
    "    \n",
    "    apks_sum, apks_count = \\\n",
    "    dataForMetrics.rdd.map(lambda x: apk(k,x[2],x[3],x[1])).map(lambda x: (x,1)).reduce(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "    map_ = apks_sum/apks_count\n",
    "    print(\"map@%s=%.3f\" %(k, map_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good enought for the purpose of this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have already finished the stage for model definition, we proceed to unpersist the data_frames that we are not going to use any more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[324] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_RDD.unpersist()\n",
    "test_RDD.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. OUR RECOMMENDER SYSTEM IN ACTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use our model to give recommendations to a new user:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can give recommendations of movies with a certain minimum number of ratings. <br>\n",
    "For that, we need to count the number of ratings per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return int(ID_and_ratings_tuple[0]), (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (ratings_corrected_final_rdd.map(lambda x: (x[1], float(x[2]))).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9200, 1), (7600, 1), (8800, 1)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rating_counts_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new user rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 260, 4), (0, 1, 3), (0, 16, 3), (0, 25, 4.5), (0, 32, 4), (0, 335, 1), (0, 379, 1), (0, 296, 3), (0, 858, 5), (0, 50, 4)]\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (0,260,4),\n",
    "     (0,1,3), \n",
    "     (0,16,3), \n",
    "     (0,25,4.5), \n",
    "     (0,32,4), \n",
    "     (0,335,1), \n",
    "     (0,379,1), \n",
    "     (0,296,3), \n",
    "     (0,858,5) , \n",
    "     (0,50,4) \n",
    "    ]\n",
    "new_user_ratings_RDD = ss.sparkContext.parallelize(new_user_ratings)\n",
    "print('New user ratings: %s' % new_user_ratings_RDD.take(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we add the new user to our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_new_ratings_RDD = ratings_corrected_final_rdd.union(new_user_ratings_RDD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we train our model with the slightly extended dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "new_ratings_model = ALS.train(data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=best_iterations, lambda_=best_reg_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before predicting rates, we are going to remove the movies whose rating was provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(105, 5659, 4.5),\n",
       " (318, 5659, 4.5),\n",
       " (249, 9613, 3.5),\n",
       " (380, 9613, 4.0),\n",
       " (1, 9413, 4.0)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_new_ratings_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9607"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will make predicitons over movies included in our data_set of ratings \n",
    "#(its number is lower than the movies dataset's)\n",
    "\n",
    "movies_training_df = data_with_new_ratings_RDD.toDF(['user','item','rating']).select('item').distinct()\n",
    "movies_training_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will make rating predicitions for the new user for every movie within the training data_set \n",
    "#but not rated yet.\n",
    "\n",
    "new_user_unrated_movies_RDD = (movies_training_df.rdd.filter(lambda x: x not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1705717180966815"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check control:\n",
    "new_ratings_model.predict(0,8440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=0, product=4056, rating=5.07765097910405),\n",
       " Rating(user=0, product=4680, rating=4.823041746720165),\n",
       " Rating(user=0, product=3016, rating=2.241652931754288)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_recommendations_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our recommendations ready!!!<br>\n",
    "Now we can print out the 25 movies with the highest predicted ratings. And join them with the movies RDD to get the titles, and ratings count in order to get movies with a minimum number of counts.<br>\n",
    "\n",
    "First we will do the join and see what the result looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create an RDD with a list of movie's titles and their corresponding keys:\n",
    "movies_title = movies_index.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4056, 5.07765097910405),\n",
       " (4680, 4.823041746720165),\n",
       " (3016, 2.241652931754288)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3050, ((3.175350789017699, 'Purgatory (1999)'), 1)),\n",
       " (2745, ((1.8920015902846288, '\"Abandoned'), 1)),\n",
       " (2440, ((3.9418588837340423, 'Love Crazy (1941)'), 1))]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then, add their corresponding title and number of times each movie's been rated:\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "new_user_recommendations_rating_RDD.join(movies_title).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to flat this down a bit in order to have (Title, Rating, Ratings Count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Purgatory (1999)', 3.175350789017699, 1),\n",
       " ('\"Abandoned', 1.8920015902846288, 1),\n",
       " ('Love Crazy (1941)', 3.9418588837340423, 1)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we get the highest rated recommendations for the new user, after removing movies with less than 25 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP-10 recommended movies (with more than 25 reviews):\n",
      "('Strangers on a Train (1951)', 5.641325674048375, 25)\n",
      "('Citizen Kane (1941)', 5.435732335278956, 69)\n",
      "('Old Boy (2003)', 5.15401514380396, 39)\n",
      "('Easy Rider (1969)', 5.149853396471215, 29)\n",
      "('Moonrise Kingdom (2012)', 5.143888156000969, 29)\n",
      "('\"African Queen', 5.106370572496246, 34)\n",
      "('\"Maltese Falcon', 5.104120647988694, 61)\n",
      "('Annie Hall (1977)', 5.086362612228669, 58)\n",
      "('There Will Be Blood (2007)', 5.069352695230904, 28)\n",
      "('Seven Samurai (Shichinin no samurai) (1954)', 5.048519820262911, 48)\n"
     ]
    }
   ],
   "source": [
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(10, key=lambda x: -x[1])\n",
    "\n",
    "print('TOP-10 recommended movies (with more than 25 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, top_movies)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ALS model seems to provide decent recommendations to new users, given the size of the training data_set.\n",
    "\n",
    "The performance of our recommender system could be improved by:<br>\n",
    "- A larger data_set (i.e.: MoviLens provides a larger data_set along with the small one we have used in this notebook).\n",
    "- More optimization of the hyperparameters of our model.\n",
    "- Using a more sophisticated algorithm.\n",
    "\n",
    "But our main target, which is its implementation with PySpark, has been met.\n",
    "\n",
    "I hope this notebook helps to make PySpark more understandable.<br>\n",
    "Thank you very much for your time!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ACKNOWLEDGMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook could be considered as a personal extension of the post by Jose A. Dianes that you can find on the following link:<br>\n",
    "https://www.codementor.io/jadianes/building-a-recommender-with-apache-spark-python-example-app-part1-du1083qbw\n",
    "\n",
    "Some of my contributions consist of:\n",
    "- Data Prepocessing (see '3.Data Prepocessing' section)\n",
    "- Showing some functionalities of ALS from Spark.ml (see '3.2) Quick look at the model (ALS)' section).\n",
    "- Hyperparameters tuning using a cross_validated grip seach strategy (see '3.3) Hyperparameters tuning' section).\n",
    "- Additional evaluation metrics (Recall and MAP) for model testing purposes (see '4.2) Additional metrics: Recall and MAP' section).\n",
    "- Using data_frames (in addition to RDDs) and SQL code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
